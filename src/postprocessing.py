"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è submission_result.csv.
–¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥:
- —É–¥–∞–ª—è—é—Ç—Å—è —Å—É—â–Ω–æ—Å—Ç–∏ –Ω–∞ –ø—Ä–æ–±–µ–ª–∞—Ö/–ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
- –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è/—Å–º–µ–∂–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞
- –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø—Ä–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è B-/I- –º–µ—Ç–∫–∏
"""

import os
import re
import torch
import pandas as pd
from data_processing import preprocess_query, tokenizer
from model import NERModel, id2label


# –ü—É—Ç–∏
DATA_DIR = "data"
INPUT_SUBMISSION = os.path.join(DATA_DIR, "submission.csv")   # –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
OUTPUT_SUBMISSION = os.path.join(DATA_DIR, "submission_result.csv")  # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
CKPT_PATH = os.path.join("model_checkpoint", "ner_model.pth")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =====================
# üîπ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ
# =====================
WORD_RE = re.compile(r"[0-9A-Za-z–ê-–Ø–∞-—è–Å—ë]+")
SPACE_RE = re.compile(r"^\s+$")


def split_entity_into_bio_spans(text: str, start: int, end: int, ent_type: str):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Å—É—â–Ω–æ—Å—Ç—å –Ω–∞ BIO-—Å–ø–∞–Ω—ã –ø–æ —Å–ª–æ–≤–∞–º (–∫–∞–∫ –≤ train)."""
    chunk = text[start:end]
    spans = [(m.start() + start, m.end() + start) for m in WORD_RE.finditer(chunk)]
    if not spans:
        return [(start, end, f"B-{ent_type}")]
    bio = []
    for i, (s, e) in enumerate(spans):
        tag = "B" if i == 0 else "I"
        bio.append((s, e, f"{tag}-{ent_type}"))
    return bio


def clean_and_merge_entities(text, entities):
    """
    –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥:
    - —É–¥–∞–ª—è–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ –Ω–∞ –ø—Ä–æ–±–µ–ª–∞—Ö/–ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è/—Å–º–µ–∂–Ω—ã–µ –≤ –æ–¥–Ω—É
    - –≤—ã—Å—Ç–∞–≤–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ B/I –º–µ—Ç–∫–∏
    """
    cleaned = []
    for start, end, tag in entities:
        chunk = text[start:end]
        if not chunk.strip():  # –ø—É—Å—Ç–æ—Ç–∞ –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã
            continue
        cleaned.append([start, end, tag])

    cleaned.sort(key=lambda x: x[0])

    merged = []
    for ent in cleaned:
        if not merged:
            merged.append(ent)
            continue

        prev = merged[-1]
        prev_type = prev[2].split("-", 1)[-1]
        curr_type = ent[2].split("-", 1)[-1]

        if ent[0] <= prev[1] and prev_type == curr_type:
            # –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∏–ª–∏ —Å–º–µ–∂–Ω—ã–µ + –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–∏–ø
            prev[1] = max(prev[1], ent[1])
        else:
            merged.append(ent)

    # –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º BIO
    final = []
    for i, (s, e, tag) in enumerate(merged):
        ent_type = tag.split("-", 1)[-1]
        if i == 0 or merged[i-1][2].split("-", 1)[-1] != ent_type:
            final.append((s, e, f"B-{ent_type}"))
        else:
            final.append((s, e, f"I-{ent_type}"))
    return final


# =====================
# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
# =====================
model = NERModel().to(device)
state = torch.load(CKPT_PATH, map_location=device)
model.load_state_dict(state)
model.eval()

# =====================
# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º submission.csv
# =====================
df = pd.read_csv(INPUT_SUBMISSION, sep=";")

# =====================
# üîπ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
# =====================
new_annotations = []

for _, row in df.iterrows():
    idx = row.get("id", row.name)  # –µ—Å–ª–∏ id –Ω–µ—Ç, –±–µ—Ä—ë–º –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏
    original_query = row.get("search_query", row.get("sample"))
    text = preprocess_query(original_query)

    enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)
    input_ids = enc["input_ids"]
    offsets = enc["offset_mapping"]

    if len(input_ids) == 0:
        new_annotations.append([])
        continue

    attn_mask = [1] * len(input_ids)
    input_ids_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)
    mask_tensor = torch.tensor([attn_mask], dtype=torch.long).to(device)

    with torch.no_grad():
        pred_tag_idxs = model(input_ids_tensor, mask_tensor)[0]  # list[int]

    pred_tags = [id2label[tag_idx] for tag_idx in pred_tag_idxs]

    # === –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º word-level —Å—É—â–Ω–æ—Å—Ç–∏ ===
    entities_pred = []
    current = None

    for tag, (start_char, end_char) in zip(pred_tags, offsets):
        if start_char == end_char:
            continue
        if tag.startswith("B-"):
            if current is not None:
                entities_pred.extend(
                    split_entity_into_bio_spans(text, current[0], current[1], current[2])
                )
            ent_type = tag.split("-", 1)[1]
            current = [start_char, end_char, ent_type]
        elif tag.startswith("I-"):
            ent_type = tag.split("-", 1)[1]
            if current is not None and current[2] == ent_type:
                current[1] = end_char
            else:
                current = [start_char, end_char, ent_type]
        else:
            if current is not None:
                entities_pred.extend(
                    split_entity_into_bio_spans(text, current[0], current[1], current[2])
                )
                current = None

    if current is not None:
        entities_pred.extend(
            split_entity_into_bio_spans(text, current[0], current[1], current[2])
        )

    # ‚úÖ –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
    entities_pred = clean_and_merge_entities(text, entities_pred)

    new_annotations.append(entities_pred)

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
df["annotation"] = new_annotations
df.to_csv(OUTPUT_SUBMISSION, sep=";", index=False)

print(f"‚úÖ Saved submission with postprocessed predictions to {OUTPUT_SUBMISSION}")
